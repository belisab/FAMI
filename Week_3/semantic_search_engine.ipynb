{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b3c9d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "import gensim\n",
    "from bs4 import BeautifulSoup\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f220ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft = api.load('fasttext-wiki-news-subwords-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b38a30d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of documents in the list is: 1225 Type of documents: <class 'str'>\n",
      "First 500 characters of the first document:\n",
      " Glutamic acid\n",
      "\n",
      "If high levels of glutamic acid are unhealthy, what would be considered a high level?\n",
      "\n",
      "\"Glutamic acid\" and \"glutamate\" are often used interchangeably but, technically, glutamate is the anionic form of glutamic acid. This article doesn't recognize that. RJII 17:01, 9 September 2005 (UTC) [ reply ]\n",
      "\n",
      "Response to above: whether it exists in the anionic or neutral form is going to be entirely dependent upon the pH - review the Henderson-Hasselbach equation. Cajolingwilhelm 01:30, 14 Fe\n"
     ]
    }
   ],
   "source": [
    "# Processing multiple HTML files in a folder\n",
    "folder_path = r\"../Week_2/wikipedia_talk_pages\"\n",
    "documents: list[str] = []\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".html\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            soup = BeautifulSoup(f.read(), \"html.parser\")\n",
    "            result = []\n",
    "\n",
    "            # page title \n",
    "            title = soup.find(\"span\", class_=\"mw-page-title-main\")\n",
    "            if title:\n",
    "                result.append(title.get_text(strip=True)) # strip removes leading/trailing whitespace\n",
    "\n",
    "            # main content\n",
    "            root = soup.find(\"div\", id=\"mw-content-text\") # we create root to be sure we are in the content section\n",
    "            content = root.find(\"div\", class_=\"mw-parser-output\") if root else None # it verifies root is not None\n",
    "            # in content, we look for h2, h3, and p tags that are direct children (not nested deeper)\n",
    "\n",
    "            if content:\n",
    "                for el in content.find_all([\"h2\", \"h3\", \"p\"], recursive=False): # recursive=False ensures we only get direct children\n",
    "                    text = el.get_text(\" \", strip=True)\n",
    "                    if text:\n",
    "                        result.append(text)\n",
    "\n",
    "            full_text = \"\\n\\n\".join(result) # every wiki page is stored as a single string with double newlines between sections\n",
    "            if full_text:   # only add non-empty documents    \n",
    "                documents.append(full_text)\n",
    "\n",
    "print(f'The number of documents in the list is: {len(documents)}', \"Type of documents:\", type(documents[0]))\n",
    "print(\"First 500 characters of the first document:\\n\", documents[0][:500]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c644a64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc_vectors = gensim.models.keyedvectors.KeyedVectors(ft.vector_size, count=len(documents))\n",
    "# for i, line in enumerate(documents):\n",
    "#     # gensim provides procedures for preprocessing and stopword removal\n",
    "#     text_without_stopwords = gensim.parsing.preprocessing.remove_stopwords(line)\n",
    "#     tokens = gensim.utils.simple_preprocess(text_without_stopwords)\n",
    "#     # the function get_mean_vector computes the average vector for all tokens\n",
    "#     dv = ft.get_mean_vector(tokens)\n",
    "#     doc_vectors.add_vector(i, dv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adcc60d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 results\n",
      "#0: Dog-like cat\n",
      "#1: Cats in New Zealand\n",
      "#2: Cat bite\n",
      "\n",
      "This article appears to be quite negative about the subject, some of my feline friends use\n",
      "#3: Geoffroy's cat\n",
      "#4: Foldex cat\n",
      "#5: Animal testing on cats\n",
      "#6: Working cat\n",
      "\n",
      "I don't really understand the correlation between feral cats and working cats. I don't \n",
      "#7: Chantilly-Tiffany\n",
      "\n",
      "My parents live in Phoenix, Arizona and own one of these cats. It is a pretty lar\n",
      "#8: Farm cat\n",
      "\n",
      "This article is useful as a portrayal of the 'working cat' in agriculture. There are a who\n",
      "#9: Cat breeds\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# Evil hack from Week 2\n",
    "sys.path.append(\"..\")\n",
    "import Search_Algorithms.semantic\n",
    "import importlib\n",
    "importlib.reload(Search_Algorithms.semantic)\n",
    "\n",
    "engine = Search_Algorithms.semantic.SemanticSearchEngine(ft, documents)\n",
    "\n",
    "while True:\n",
    "    query = input(\"Hi! What do you want to search for?\").lower().strip()\n",
    "    if query == \"\":\n",
    "        break\n",
    "    r = engine.search(query, topn=10)\n",
    "    print(f\"Found {len(r)} results\")\n",
    "    for i, d in enumerate(r):\n",
    "        print(f\"#{i}: {d[:100]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
